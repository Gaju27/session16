{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The files are:\n",
    "\n",
    "1. personal_info.csv - personal information such as name, gender, etc. (one row per person)\n",
    "2. vehicles.csv - what vehicle people own (one row per person)\n",
    "3. employment.csv - where a person is employed (one row per person)\n",
    "4. update_status.csv - when the person's data was created and last updated\n",
    "\n",
    "Each file contains a key, SSN, which uniquely identifies a person.\n",
    "\n",
    "This key is present in all four files.\n",
    "\n",
    "You are guaranteed that the same SSN value is present in every file, and that it only appears once per file.\n",
    "\n",
    "In addition, the files are all sorted by SSN, i.e. the SSN values appear in the same order in each file.\n",
    "\n",
    "### Goal 1\n",
    "Your first task is to create iterators for each of the four files that contained cleaned up data, of the correct type (e.g. string, int, date, etc), and represented by a named tuple.\n",
    "\n",
    "For now these four iterators are just separate, independent iterators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let see how data looks in each csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssn,first_name,last_name,gender,language\n",
      "\n",
      "100-53-9824,Sebastiano,Tester,Male,Icelandic\n",
      "\n",
      "101-71-4702,Cayla,MacDonagh,Female,Lao\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('personal_info.csv') as file:\n",
    "    file_vals=iter(file)\n",
    "    for i,vals in enumerate(file_vals):\n",
    "        print(vals)\n",
    "        if i == 2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_info_type = ['INT', 'STRING', 'STRING', 'STRING','STRING']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssn,vehicle_make,vehicle_model,model_year\n",
      "\n",
      "100-53-9824,Oldsmobile,Bravada,1993\n",
      "\n",
      "101-71-4702,Ford,Mustang,1997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('vehicles.csv') as file:\n",
    "    file_vals=iter(file)\n",
    "    for i,vals in enumerate(file_vals):\n",
    "        print(vals)\n",
    "        if i == 2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_type= ['INT','STRING','STRING','INT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employer,department,employee_id,ssn\n",
      "\n",
      "Stiedemann-Bailey,Research and Development,29-0890771,100-53-9824\n",
      "\n",
      "Nicolas and Sons,Sales,41-6841359,101-71-4702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('employment.csv') as file:\n",
    "    file_vals=iter(file)\n",
    "    for i,vals in enumerate(file_vals):\n",
    "        print(vals)\n",
    "        if i == 2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "employment_type = ['STRING','STRING','INT','INT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssn,last_updated,created\n",
      "\n",
      "100-53-9824,2017-10-07T00:14:42Z,2016-01-24T21:19:30Z\n",
      "\n",
      "101-71-4702,2017-01-23T11:23:17Z,2016-01-27T04:32:57Z\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('update_status.csv') as file:\n",
    "    file_vals=iter(file)\n",
    "    for i,vals in enumerate(file_vals):\n",
    "        print(vals)\n",
    "        if i == 2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_type = ['INT','DATE','DATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def type_casting(col_data,input_val):\n",
    "    if col_data == 'DATE':\n",
    "        return datetime.strptime(input_val, '%Y-%m-%dT%H:%M:%SZ').date()\n",
    "    elif col_data == 'INT':\n",
    "        return int(input_val.replace('-','_'))\n",
    "    else:\n",
    "        return input_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_each_row(col_data_type,row_val):\n",
    "    return [type_casting(col_data, value) for col_data, value in zip(col_data_type, row_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import csv\n",
    "from itertools import islice\n",
    "def gen_fun(input_file,col_data_type):\n",
    "    with open(input_file) as f:\n",
    "        rows = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "        headers = next(iter(rows))\n",
    "        named_tuple = namedtuple(input_file.replace('.','_'), headers)\n",
    "        for row in rows:\n",
    "            yield named_tuple(*cast_each_row(col_data_type, row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personal_info_csv(ssn=100539824, first_name='Sebastiano', last_name='Tester', gender='Male', language='Icelandic')\n",
      "personal_info_csv(ssn=101714702, first_name='Cayla', last_name='MacDonagh', gender='Female', language='Lao')\n",
      "personal_info_csv(ssn=101840356, first_name='Nomi', last_name='Lipprose', gender='Female', language='Yiddish')\n"
     ]
    }
   ],
   "source": [
    "file_path1='personal_info.csv'\n",
    "\n",
    "personal_data = gen_fun(file_path1,personal_info_type)\n",
    "for data in islice(personal_data, 3):\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vehicles_csv(ssn=100539824, vehicle_make='Oldsmobile', vehicle_model='Bravada', model_year=1993)\n",
      "vehicles_csv(ssn=101714702, vehicle_make='Ford', vehicle_model='Mustang', model_year=1997)\n",
      "vehicles_csv(ssn=101840356, vehicle_make='GMC', vehicle_model='Yukon', model_year=2005)\n"
     ]
    }
   ],
   "source": [
    "file_path2='vehicles.csv'\n",
    "\n",
    "vehicles_data = gen_fun(file_path2,vehicles_type)\n",
    "for data in islice(vehicles_data, 3):\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employment_csv(employer='Stiedemann-Bailey', department='Research and Development', employee_id=290890771, ssn=100539824)\n",
      "employment_csv(employer='Nicolas and Sons', department='Sales', employee_id=416841359, ssn=101714702)\n",
      "employment_csv(employer='Connelly Group', department='Research and Development', employee_id=987952860, ssn=101840356)\n"
     ]
    }
   ],
   "source": [
    "file_path3='employment.csv'\n",
    "\n",
    "employment_data = gen_fun(file_path3,employment_type)\n",
    "for data in islice(employment_data, 3):\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update_status_csv(ssn=100539824, last_updated=datetime.date(2017, 10, 7), created=datetime.date(2016, 1, 24))\n",
      "update_status_csv(ssn=101714702, last_updated=datetime.date(2017, 1, 23), created=datetime.date(2016, 1, 27))\n",
      "update_status_csv(ssn=101840356, last_updated=datetime.date(2017, 10, 4), created=datetime.date(2016, 9, 21))\n"
     ]
    }
   ],
   "source": [
    "file_path4='update_status.csv'\n",
    "\n",
    "status_data = gen_fun(file_path4,status_type)\n",
    "for data in islice(status_data, 3):\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Goal 2\n",
    "Create a single iterable that combines all the columns from all the iterators.\n",
    "\n",
    "The iterable should yield named tuples containing all the columns. Make sure that the SSN's across the files match!\n",
    "\n",
    "All the files are guaranteed to be in SSN sort order, and every SSN is unique, and every SSN appears in every file.\n",
    "\n",
    "Make sure the SSN is not repeated 4 times - one time per row is enough!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssn_match():\n",
    "    for pers, emp, vehi, upd in zip(personal_data, employment_data, vehicles_data, status_data):\n",
    "        all_fields = pers._fields + emp._fields + vehi._fields + upd._fields\n",
    "        ssn_match_info = namedtuple(\"ssn_match_info\", sorted(set(all_fields), key=all_fields.index))\n",
    "        final_data = [*pers, *emp, *vehi, *upd]\n",
    "        yield ssn_match_info(*sorted(set(final_data), key=final_data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssn_match_info(ssn=105857486, first_name='Angelina', last_name='McAvey', gender='Female', language='Punjabi', employer='Roberts, Torphy and Dach', department='Human Resources', employee_id=774895332, vehicle_make='Chrysler', vehicle_model='300', model_year=2008, last_updated=datetime.date(2018, 2, 14), created=datetime.date(2016, 12, 15))\n",
      "ssn_match_info(ssn=105915022, first_name='Moselle', last_name='Apfel', gender='Female', language='Latvian', employer='Lind-Jast', department='Marketing', employee_id=796418731, vehicle_make='Isuzu', vehicle_model='Hombre Space', model_year=2000, last_updated=datetime.date(2018, 3, 24), created=datetime.date(2016, 3, 24))\n",
      "ssn_match_info(ssn=105917777, first_name='Audi', last_name='Roach', gender='Female', language='Estonian', employer='Bashirian-Lueilwitz', department='Engineering', employee_id=443328799, vehicle_make='Chevrolet', vehicle_model='Silverado 3500', model_year=2004, last_updated=datetime.date(2017, 5, 11), created=datetime.date(2016, 5, 31))\n"
     ]
    }
   ],
   "source": [
    "ssn_matched=ssn_match()\n",
    "for data in islice(ssn_matched, 3):\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goal 3\n",
    "\n",
    "Next, you want to identify any stale records, where stale simply means the record has not been updated since 3/1/2017 (e.g. last update date < 3/1/2017). Create an iterator that only contains current records (i.e. not stale) based on the last_updated field from the status_update file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stale_records(input_date):\n",
    "    date = datetime.strptime(input_date, '%d-%m-%Y').date()\n",
    "    for ssn_matched_data in ssn_match():\n",
    "        if ssn_matched_data.last_updated < date:\n",
    "            yield ssn_matched_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_date = '11-01-2018'\n",
    "stale_record=stale_records(input_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssn_match_info(ssn=106351938, first_name='Mackenzie', last_name='Nussey', gender='Male', language='Swedish', employer='Windler, Marks and Haley', department='Services', employee_id=546271885, vehicle_make='GMC', vehicle_model='Sonoma Club', model_year=1992, last_updated=datetime.date(2017, 10, 21), created=datetime.date(2016, 9, 8))\n",
      "ssn_match_info(ssn=106363293, first_name='Martino', last_name='Tregoning', gender='Male', language='Tok Pisin', employer='Leffler-Hahn', department='Accounting', employee_id=315735282, vehicle_make='Volkswagen', vehicle_model='Touareg', model_year=2008, last_updated=datetime.date(2017, 3, 18), created=datetime.date(2016, 5, 16))\n",
      "ssn_match_info(ssn=110843641, first_name='Amberly', last_name='Huws', gender='Female', language='Papiamento', employer='Lueilwitz LLC', department='Marketing', employee_id=339146042, vehicle_make='Ford', vehicle_model='Mustang', model_year=1990, last_updated=datetime.date(2017, 9, 4), created=datetime.date(2016, 9, 12))\n",
      "ssn_match_info(ssn=111351034, first_name='Giacopo', last_name='Timperley', gender='Male', language='Gagauz', employer='Davis Inc', department='Accounting', employee_id=390400385, vehicle_make='Ford', vehicle_model='Fiesta', model_year=2001, last_updated=datetime.date(2017, 3, 18), created=datetime.date(2016, 8, 21))\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "for data in islice(stale_record, 4):\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goal 4\n",
    "Find the largest group of car makes for each gender.\n",
    "\n",
    "Possibly more than one such group per gender exists (equal sizes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_record = ssn_match()\n",
    "make_count_male = dict()\n",
    "make_count_female = dict()\n",
    "for _ in all_record:\n",
    "    if _.gender == 'Male':\n",
    "        make_count_male[_.vehicle_make] = make_count_male[_.vehicle_make] + 1 if _.vehicle_make in make_count_male else 1\n",
    "    else:\n",
    "        make_count_female[_.vehicle_make] = make_count_female[_.vehicle_make] + 1 if _.vehicle_make in make_count_female else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Ford', 41)]\n"
     ]
    }
   ],
   "source": [
    "max_value = max(list(make_count_male.values()))\n",
    "print([(k, v) for k, v in make_count_male.items() if v == max_value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Chevrolet', 47)]\n"
     ]
    }
   ],
   "source": [
    "max_value = max(list(make_count_female.values()))\n",
    "print([(k, v) for k, v in make_count_female.items() if v == max_value])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
